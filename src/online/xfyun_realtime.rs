use base64::{engine::general_purpose, Engine};
use chrono::Utc;
use futures::{SinkExt, StreamExt};
use hmac::{Hmac, Mac};
use sha2::Sha256;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use tokio::sync::Mutex;
use tokio_tungstenite::{connect_async, tungstenite::Message};
use urlencoding::encode;
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use cpal::{Sample, SampleFormat, StreamConfig};

use crate::utils::{Result, VoiceInputError};

type HmacSha256 = Hmac<Sha256>;

/// è®¯é£äº‘å®æ—¶è¯­éŸ³è¯†åˆ«å™¨
pub struct XfyunRealtimeRecognizer {
    app_id: String,
    api_secret: String,
    api_key: String,
}

impl XfyunRealtimeRecognizer {
    /// åˆ›å»ºæ–°çš„è®¯é£äº‘å®æ—¶è¯†åˆ«å™¨
    pub fn new(app_id: String, api_secret: String, api_key: String) -> Self {
        Self {
            app_id,
            api_secret,
            api_key,
        }
    }

    /// ç”Ÿæˆé‰´æƒ URL
    fn generate_auth_url(&self) -> Result<String> {
        let host = "iat-api.xfyun.cn";
        let path = "/v2/iat";
        let date = Utc::now().format("%a, %d %b %Y %H:%M:%S GMT").to_string();

        // ç”Ÿæˆç­¾ååŸæ–‡
        let signature_origin = format!("host: {}\ndate: {}\nGET {} HTTP/1.1", host, date, path);

        // HMAC-SHA256 åŠ å¯†
        let mut mac = HmacSha256::new_from_slice(self.api_secret.as_bytes())
            .map_err(|e| VoiceInputError::Recognition(format!("HMAC åˆå§‹åŒ–å¤±è´¥: {}", e)))?;
        mac.update(signature_origin.as_bytes());
        let signature = general_purpose::STANDARD.encode(mac.finalize().into_bytes());

        // ç”Ÿæˆ authorization
        let authorization_origin = format!(
            "api_key=\"{}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{}\"",
            self.api_key, signature
        );
        let authorization = general_purpose::STANDARD.encode(authorization_origin);

        // ç”Ÿæˆæœ€ç»ˆ URL
        let url = format!(
            "wss://{}{}?authorization={}&date={}&host={}",
            host,
            path,
            encode(&authorization),
            encode(&date),
            host
        );

        tracing::debug!("ç”Ÿæˆé‰´æƒ URL: {}", url);
        Ok(url)
    }

    /// å®æ—¶æµå¼è¯†åˆ«ï¼ˆè¾¹å½•è¾¹å‘é€ï¼‰
    pub async fn recognize_realtime(
        &self,
        sample_rate: u32,
        silence_duration: f32,
    ) -> Result<String> {
        println!("ğŸŒ æ­£åœ¨è¿æ¥è®¯é£è¯­éŸ³è¯†åˆ«æœåŠ¡...");

        // ç”Ÿæˆé‰´æƒ URL
        let url = self.generate_auth_url()?;
        tracing::debug!("WebSocket URL: {}", url);

        // å»ºç«‹ WebSocket è¿æ¥
        println!("æ­£åœ¨å»ºç«‹ WebSocket è¿æ¥...");
        let (ws_stream, _) = connect_async(&url)
            .await
            .map_err(|e| VoiceInputError::Recognition(format!("WebSocket è¿æ¥å¤±è´¥: {}", e)))?;

        println!("âœ… è¿æ¥æˆåŠŸ\n");

        let (write, mut read) = ws_stream.split();
        let result = Arc::new(Mutex::new(String::new()));
        let result_clone = result.clone();
        let is_running = Arc::new(AtomicBool::new(true));
        let is_running_for_ctrlc = is_running.clone();
        let is_running_for_receive = is_running.clone();

        // Ctrl+C å¤„ç†
        ctrlc::set_handler(move || {
            println!("\n\nâ¹ï¸  ç”¨æˆ·åœæ­¢å½•éŸ³...");
            is_running_for_ctrlc.store(false, Ordering::SeqCst);
        })
        .ok();

        // å¯åŠ¨æ¥æ”¶ä»»åŠ¡
        let receive_task = tokio::spawn(async move {
            while let Some(msg) = read.next().await {
                match msg {
                    Ok(Message::Text(text)) => {
                        tracing::debug!("æ”¶åˆ°æ¶ˆæ¯: {}", text);

                        // è§£æè¿”å›ç»“æœ
                        if let Ok(response) = serde_json::from_str::<serde_json::Value>(&text) {
                            // æ£€æŸ¥é”™è¯¯
                            if let Some(code) = response.get("code") {
                                if code.as_i64() != Some(0) {
                                    if let Some(message) = response.get("message") {
                                        tracing::error!("è¯†åˆ«é”™è¯¯: {}", message);
                                    }
                                    break;
                                }
                            }

                            // æå–è¯†åˆ«ç»“æœ
                            if let Some(data) = response.get("data") {
                                if let Some(result_obj) = data.get("result") {
                                    if let Some(ws) = result_obj.get("ws") {
                                        if let Some(ws_array) = ws.as_array() {
                                            let mut text_result = String::new();
                                            for item in ws_array {
                                                if let Some(cw) = item.get("cw") {
                                                    if let Some(cw_array) = cw.as_array() {
                                                        for word in cw_array {
                                                            if let Some(w) = word.get("w") {
                                                                if let Some(w_str) = w.as_str() {
                                                                    text_result.push_str(w_str);
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            if !text_result.is_empty() {
                                                let mut result_lock = result_clone.lock().await;
                                                result_lock.push_str(&text_result);
                                                // å®æ—¶æ˜¾ç¤º
                                                print!("\rè¯†åˆ«ä¸­: {}", result_lock);
                                                use std::io::Write;
                                                std::io::stdout().flush().ok();
                                            }
                                        }
                                    }
                                }

                                // æ£€æŸ¥æ˜¯å¦ç»“æŸï¼ˆè®¯é£äº‘ VAD æ£€æµ‹åˆ°é™éŸ³ï¼‰
                                if let Some(status) = data.get("status") {
                                    if status.as_i64() == Some(2) {
                                        println!("\nğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³");
                                        tracing::info!("âœ… è¯†åˆ«å®Œæˆ");
                                        // é€šçŸ¥å‘é€ç«¯åœæ­¢
                                        is_running_for_receive.store(false, Ordering::SeqCst);
                                        break;
                                    }
                                }
                            }
                        }
                    }
                    Ok(Message::Close(_)) => {
                        tracing::info!("WebSocket è¿æ¥å…³é—­");
                        break;
                    }
                    Err(e) => {
                        tracing::error!("æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {}", e);
                        break;
                    }
                    _ => {}
                }
            }
        });

        // å½•éŸ³å¹¶å‘é€
        let app_id = self.app_id.clone();
        let send_result = self.record_and_send(
            write,
            sample_rate,
            app_id,
            is_running,
            silence_duration,
        ).await;

        // ç­‰å¾…æ¥æ”¶å®Œæˆ
        receive_task.await.map_err(|e| {
            VoiceInputError::Recognition(format!("æ¥æ”¶ä»»åŠ¡å¤±è´¥: {}", e))
        })?;

        // æ£€æŸ¥å‘é€æ˜¯å¦å‡ºé”™
        send_result?;

        let final_result = result.lock().await.clone();
        println!("\n");  // æ¢è¡Œ
        Ok(final_result)
    }

    /// å½•éŸ³å¹¶å®æ—¶å‘é€
    async fn record_and_send(
        &self,
        mut write: futures::stream::SplitSink<
            tokio_tungstenite::WebSocketStream<
                tokio_tungstenite::MaybeTlsStream<tokio::net::TcpStream>
            >,
            Message
        >,
        sample_rate: u32,
        app_id: String,
        is_running: Arc<AtomicBool>,
        silence_duration: f32,
    ) -> Result<()> {
        // è·å–éŸ³é¢‘è®¾å¤‡
        let host = cpal::default_host();
        let device = host
            .default_input_device()
            .ok_or(VoiceInputError::NoMicrophone)?;

        tracing::info!("ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {}", device.name().unwrap_or_else(|_| "Unknown".to_string()));

        // é…ç½®éŸ³é¢‘æµ
        let config = StreamConfig {
            channels: 1,
            sample_rate: cpal::SampleRate(sample_rate),
            buffer_size: cpal::BufferSize::Default,
        };

        // éŸ³é¢‘ç¼“å†²åŒºï¼ˆç”¨äºæ”¶é›† 40ms çš„æ•°æ®ï¼‰
        let frame_size = (sample_rate as f32 * 0.04) as usize; // 40ms
        let buffer = Arc::new(std::sync::Mutex::new(Vec::with_capacity(frame_size * 2)));

        // æ„å»ºéŸ³é¢‘æµ
        let supported_config = device
            .supported_input_configs()
            .map_err(|e| VoiceInputError::AudioDevice(format!("è·å–è®¾å¤‡é…ç½®å¤±è´¥: {}", e)))?
            .next()
            .ok_or_else(|| VoiceInputError::AudioDevice("è®¾å¤‡ä¸æ”¯æŒä»»ä½•é…ç½®".to_string()))?;

        let sample_format = supported_config.sample_format();

        let stream = match sample_format {
            SampleFormat::F32 => {
                let buffer_clone = Arc::clone(&buffer);
                device.build_input_stream(
                    &config,
                    move |data: &[f32], _: &cpal::InputCallbackInfo| {
                        let mut buf = buffer_clone.lock().unwrap();
                        buf.extend_from_slice(data);
                    },
                    |err| {
                        tracing::error!("å½•éŸ³é”™è¯¯: {}", err);
                    },
                    None,
                )
            }
            SampleFormat::I16 => {
                let buffer_clone = Arc::clone(&buffer);
                device.build_input_stream(
                    &config,
                    move |data: &[i16], _: &cpal::InputCallbackInfo| {
                        let mut buf = buffer_clone.lock().unwrap();
                        buf.extend(data.iter().map(|&s| s.to_float_sample()));
                    },
                    |err| {
                        tracing::error!("å½•éŸ³é”™è¯¯: {}", err);
                    },
                    None,
                )
            }
            SampleFormat::U16 => {
                let buffer_clone = Arc::clone(&buffer);
                device.build_input_stream(
                    &config,
                    move |data: &[u16], _: &cpal::InputCallbackInfo| {
                        let mut buf = buffer_clone.lock().unwrap();
                        buf.extend(data.iter().map(|&s| s.to_float_sample()));
                    },
                    |err| {
                        tracing::error!("å½•éŸ³é”™è¯¯: {}", err);
                    },
                    None,
                )
            }
            SampleFormat::I8 => {
                let buffer_clone = Arc::clone(&buffer);
                device.build_input_stream(
                    &config,
                    move |data: &[i8], _: &cpal::InputCallbackInfo| {
                        let mut buf = buffer_clone.lock().unwrap();
                        buf.extend(data.iter().map(|&s| s.to_float_sample()));
                    },
                    |err| {
                        tracing::error!("å½•éŸ³é”™è¯¯: {}", err);
                    },
                    None,
                )
            }
            SampleFormat::U8 => {
                let buffer_clone = Arc::clone(&buffer);
                device.build_input_stream(
                    &config,
                    move |data: &[u8], _: &cpal::InputCallbackInfo| {
                        let mut buf = buffer_clone.lock().unwrap();
                        buf.extend(data.iter().map(|&s| s.to_float_sample()));
                    },
                    |err| {
                        tracing::error!("å½•éŸ³é”™è¯¯: {}", err);
                    },
                    None,
                )
            }
            _ => {
                return Err(VoiceInputError::AudioDevice(format!(
                    "ä¸æ”¯æŒçš„é‡‡æ ·æ ¼å¼: {:?}",
                    sample_format
                )))
            }
        }
        .map_err(|e| VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e)))?;

        // å¼€å§‹å½•éŸ³
        stream.play().map_err(|e| {
            VoiceInputError::AudioRecord(format!("å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: {}", e))
        })?;

        println!("ğŸ¤ å¼€å§‹å½•éŸ³... (æŒ‰ Ctrl+C åœæ­¢)");
        println!("ğŸ’¡ è¯´å®Œè¯åä¿æŒé™éŸ³ {:.1} ç§’å³å¯è‡ªåŠ¨åœæ­¢\n", silence_duration);

        let mut status = 0; // 0: é¦–å¸§, 1: ä¸­é—´å¸§, 2: æœ«å¸§

        // å°†é™éŸ³æŒç»­æ—¶é—´è½¬æ¢ä¸ºæ¯«ç§’ï¼ˆè®¯é£äº‘ vad_eos å‚æ•°ï¼‰
        let vad_eos = (silence_duration * 1000.0) as u32;

        // å‘é€éŸ³é¢‘å¸§
        while is_running.load(Ordering::SeqCst) {
            tokio::time::sleep(tokio::time::Duration::from_millis(40)).await;

            // è¯»å–ç¼“å†²åŒºæ•°æ®
            let audio_data = {
                let mut buf = buffer.lock().unwrap();
                if buf.len() < frame_size {
                    continue;
                }
                let data: Vec<f32> = buf.drain(..frame_size).collect();
                data
            };

            // è½¬æ¢ä¸º 16-bit PCM
            let pcm_data: Vec<i16> = audio_data.iter().map(|&s| (s * 32767.0) as i16).collect();
            let bytes: Vec<u8> = pcm_data
                .iter()
                .flat_map(|&s: &i16| s.to_le_bytes())
                .collect();

            let audio_b64 = general_purpose::STANDARD.encode(&bytes);

            // æ„å»ºæ¶ˆæ¯
            let frame_msg = if status == 0 {
                // é¦–å¸§
                serde_json::json!({
                    "common": {
                        "app_id": app_id
                    },
                    "business": {
                        "language": "zh_cn",
                        "domain": "iat",
                        "accent": "mandarin",
                        "vad_eos": vad_eos  // ä½¿ç”¨é…ç½®çš„é™éŸ³è¶…æ—¶æ—¶é—´
                    },
                    "data": {
                        "status": 0,
                        "format": "audio/L16;rate=16000",
                        "encoding": "raw",
                        "audio": audio_b64
                    }
                })
            } else {
                // ä¸­é—´å¸§
                serde_json::json!({
                    "data": {
                        "status": 1,
                        "format": "audio/L16;rate=16000",
                        "encoding": "raw",
                        "audio": audio_b64
                    }
                })
            };

            // å‘é€
            if let Err(e) = write.send(Message::Text(frame_msg.to_string())).await {
                tracing::warn!("å‘é€éŸ³é¢‘å¤±è´¥: {}", e);
                break;
            }

            if status == 0 {
                status = 1;
            }
        }

        // å‘é€ç»“æŸå¸§
        let end_frame = serde_json::json!({
            "data": {
                "status": 2,
                "format": "audio/L16;rate=16000",
                "encoding": "raw",
                "audio": ""
            }
        });

        write.send(Message::Text(end_frame.to_string())).await.ok();
        tokio::time::sleep(tokio::time::Duration::from_millis(200)).await;

        // åœæ­¢å½•éŸ³
        drop(stream);

        Ok(())
    }
}
