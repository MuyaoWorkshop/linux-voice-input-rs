use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use cpal::{Device, Sample, SampleFormat, Stream, StreamConfig};
use std::sync::{Arc, Mutex};
use std::time::Duration;

use crate::audio::silence::SilenceDetector;
use crate::utils::{Result, VoiceInputError};

/// éŸ³é¢‘ç¼“å†²åŒº
pub type AudioBuffer = Vec<f32>;

/// éŸ³é¢‘å½•åˆ¶å™¨
pub struct AudioRecorder {
    device: Device,
    config: StreamConfig,
    sample_rate: u32,
}

impl AudioRecorder {
    /// åˆ›å»ºæ–°çš„éŸ³é¢‘å½•åˆ¶å™¨
    pub fn new(sample_rate: u32, channels: u16) -> Result<Self> {
        // è·å–é»˜è®¤éŸ³é¢‘ä¸»æœº
        let host = cpal::default_host();

        // è·å–é»˜è®¤è¾“å…¥è®¾å¤‡ï¼ˆéº¦å…‹é£ï¼‰
        let device = host
            .default_input_device()
            .ok_or(VoiceInputError::NoMicrophone)?;

        tracing::info!("ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {}", device.name().unwrap_or_else(|_| "Unknown".to_string()));

        // é…ç½®éŸ³é¢‘æµ
        let config = StreamConfig {
            channels,
            sample_rate: cpal::SampleRate(sample_rate),
            buffer_size: cpal::BufferSize::Default,
        };

        Ok(Self {
            device,
            config,
            sample_rate,
        })
    }

    /// å½•åˆ¶éŸ³é¢‘ç›´åˆ°é™éŸ³ï¼ˆç¦»çº¿æ¨¡å¼ä½¿ç”¨ï¼‰
    pub fn record_until_silence(
        &self,
        max_duration: Duration,
        silence_threshold: f32,
        silence_duration: f32,
    ) -> Result<AudioBuffer> {
        let mut silence_detector = SilenceDetector::new(
            silence_threshold,
            Duration::from_secs_f32(silence_duration),
        );

        let buffer = Arc::new(Mutex::new(Vec::new()));
        let buffer_clone = Arc::clone(&buffer);

        let err_occurred = Arc::new(Mutex::new(None));
        let err_clone = Arc::clone(&err_occurred);

        // æ„å»ºéŸ³é¢‘æµ
        let stream = self.build_input_stream(
            move |data: &[f32]| {
                let mut buf = buffer_clone.lock().unwrap();
                buf.extend_from_slice(data);

                // æ˜¾ç¤ºéŸ³é‡æ¡
                SilenceDetector::print_volume_bar(data);
            },
            move |err| {
                *err_clone.lock().unwrap() = Some(err);
            },
        )?;

        // å¼€å§‹å½•éŸ³
        stream.play().map_err(|e| {
            VoiceInputError::AudioRecord(format!("å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: {}", e))
        })?;

        println!("ğŸ¤ å¼€å§‹å½•éŸ³... (åœé¡¿ {:.1} ç§’è‡ªåŠ¨ç»“æŸ)", silence_duration);

        let start_time = std::time::Instant::now();
        let chunk_duration = Duration::from_millis(100); // æ¯ 100ms æ£€æŸ¥ä¸€æ¬¡

        loop {
            std::thread::sleep(chunk_duration);

            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if let Some(err) = err_occurred.lock().unwrap().take() {
                return Err(VoiceInputError::AudioRecord(format!("å½•éŸ³é”™è¯¯: {}", err)));
            }

            // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if start_time.elapsed() > max_duration {
                println!("\nâ±ï¸  è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œåœæ­¢å½•éŸ³");
                break;
            }

            // æ£€æŸ¥é™éŸ³
            let buf = buffer.lock().unwrap();
            if buf.len() > self.sample_rate as usize {
                // å–æœ€å 0.5 ç§’çš„æ•°æ®æ£€æµ‹é™éŸ³
                let check_size = (self.sample_rate as f32 * 0.5) as usize;
                let start_idx = buf.len().saturating_sub(check_size);
                let recent_samples = &buf[start_idx..];

                if silence_detector.detect(recent_samples) {
                    println!("\nğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³");
                    break;
                }
            }
        }

        // åœæ­¢å½•éŸ³
        drop(stream);

        let result = Arc::try_unwrap(buffer)
            .unwrap_or_else(|arc| {
                let mutex = Mutex::new(arc.lock().unwrap().clone());
                mutex
            })
            .into_inner()
            .unwrap();

        println!("âœ… å½•éŸ³å®Œæˆï¼Œæ—¶é•¿: {:.2} ç§’", result.len() as f32 / self.sample_rate as f32);

        Ok(result)
    }

    /// æ„å»ºè¾“å…¥éŸ³é¢‘æµ
    fn build_input_stream<D, E>(
        &self,
        data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let supported_config = self
            .device
            .supported_input_configs()
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("è·å–è®¾å¤‡é…ç½®å¤±è´¥: {}", e))
            })?
            .next()
            .ok_or_else(|| {
                VoiceInputError::AudioDevice("è®¾å¤‡ä¸æ”¯æŒä»»ä½•é…ç½®".to_string())
            })?;

        let sample_format = supported_config.sample_format();

        tracing::debug!(
            "ä½¿ç”¨é‡‡æ ·æ ¼å¼: {:?}, é‡‡æ ·ç‡: {}",
            sample_format,
            self.sample_rate
        );

        // æ ¹æ®æ ·æœ¬æ ¼å¼æ„å»ºæµ
        match sample_format {
            SampleFormat::F32 => self.build_stream_f32(data_callback, error_callback),
            SampleFormat::I16 => self.build_stream_i16(data_callback, error_callback),
            SampleFormat::U16 => self.build_stream_u16(data_callback, error_callback),
            SampleFormat::I8 => self.build_stream_i8(data_callback, error_callback),
            SampleFormat::U8 => self.build_stream_u8(data_callback, error_callback),
            _ => Err(VoiceInputError::AudioDevice(format!(
                "ä¸æ”¯æŒçš„é‡‡æ ·æ ¼å¼: {:?}",
                sample_format
            ))),
        }
    }

    /// æ„å»º f32 ç±»å‹çš„éŸ³é¢‘æµ
    fn build_stream_f32<D, E>(
        &self,
        mut data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let stream = self
            .device
            .build_input_stream(
                &self.config,
                move |data: &[f32], _: &cpal::InputCallbackInfo| {
                    data_callback(data);
                },
                error_callback,
                None,
            )
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e))
            })?;

        Ok(stream)
    }

    /// æ„å»º i16 ç±»å‹çš„éŸ³é¢‘æµ
    fn build_stream_i16<D, E>(
        &self,
        mut data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let stream = self
            .device
            .build_input_stream(
                &self.config,
                move |data: &[i16], _: &cpal::InputCallbackInfo| {
                    let samples: Vec<f32> = data.iter().map(|&s| s.to_float_sample()).collect();
                    data_callback(&samples);
                },
                error_callback,
                None,
            )
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e))
            })?;

        Ok(stream)
    }

    /// æ„å»º u16 ç±»å‹çš„éŸ³é¢‘æµ
    fn build_stream_u16<D, E>(
        &self,
        mut data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let stream = self
            .device
            .build_input_stream(
                &self.config,
                move |data: &[u16], _: &cpal::InputCallbackInfo| {
                    let samples: Vec<f32> = data.iter().map(|&s| s.to_float_sample()).collect();
                    data_callback(&samples);
                },
                error_callback,
                None,
            )
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e))
            })?;

        Ok(stream)
    }

    /// æ„å»º i8 ç±»å‹çš„éŸ³é¢‘æµ
    fn build_stream_i8<D, E>(
        &self,
        mut data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let stream = self
            .device
            .build_input_stream(
                &self.config,
                move |data: &[i8], _: &cpal::InputCallbackInfo| {
                    let samples: Vec<f32> = data.iter().map(|&s| s.to_float_sample()).collect();
                    data_callback(&samples);
                },
                error_callback,
                None,
            )
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e))
            })?;

        Ok(stream)
    }

    /// æ„å»º u8 ç±»å‹çš„éŸ³é¢‘æµ
    fn build_stream_u8<D, E>(
        &self,
        mut data_callback: D,
        error_callback: E,
    ) -> Result<Stream>
    where
        D: FnMut(&[f32]) + Send + 'static,
        E: FnMut(cpal::StreamError) + Send + 'static,
    {
        let stream = self
            .device
            .build_input_stream(
                &self.config,
                move |data: &[u8], _: &cpal::InputCallbackInfo| {
                    let samples: Vec<f32> = data.iter().map(|&s| s.to_float_sample()).collect();
                    data_callback(&samples);
                },
                error_callback,
                None,
            )
            .map_err(|e| {
                VoiceInputError::AudioDevice(format!("æ„å»ºéŸ³é¢‘æµå¤±è´¥: {}", e))
            })?;

        Ok(stream)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_recorder_creation() {
        // è¿™ä¸ªæµ‹è¯•å¯èƒ½åœ¨ CI ç¯å¢ƒä¸­å¤±è´¥ï¼ˆæ²¡æœ‰éŸ³é¢‘è®¾å¤‡ï¼‰
        // ä»…åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒè¿è¡Œ
        if std::env::var("CI").is_err() {
            let recorder = AudioRecorder::new(16000, 1);
            // å¦‚æœæœ‰éº¦å…‹é£åº”è¯¥æˆåŠŸ
            if let Ok(rec) = recorder {
                assert_eq!(rec.sample_rate, 16000);
            }
        }
    }
}
